{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i2.wp.com/hackwagon.com/wp-content/uploads/2017/02/Logo-Web-Export.png?ssl=1\" width=200/></center>\n",
    "<h1> Hackwagon Academy DS102 Lesson 5A </h1>\n",
    "<h2> Näive Bayes Classification</h2> \n",
    "<h3> Lesson Outline </h3>\n",
    "\n",
    "- 1. [Näive Bayes Classification](#1)\n",
    "    - 1.1 [Problem Setup](#1.1)\n",
    "    - 1.2 [Derivation](#1.2)\n",
    "- 2. [Vectorizer](#2)\n",
    "- 3. [Applied Naive Bayes - Popcorn Reviews](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn Installation\n",
    "\n",
    "**Note:**  Your anaconda installation would have included Scikit-learn by default.  If you do not have it, it is better to install it from the Anaconda Environment.  **[See Guide](https://docs.google.com/document/d/15GcqJEV4-6aJ9vHgIywNL-PuFWuyz2MN6wBbsGIuix8/edit?usp=sharing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "<a id='1'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;</font><font color=\"salmon\"> Scikit Learn - SKLearn </font> </h2></a>\n",
    "\n",
    "<a id='1.1'><h3>5 Standard Steps</h3></a>\n",
    "\n",
    "**Step 1**: Choose a class of machine learning model from the library \n",
    "\n",
    "**Step 2**: Choose the model’s hyperparameters by instantiating with desired values (tuning)\n",
    "\n",
    "**Step 3**: Arrange data into features and target\n",
    "\n",
    "**Step 4**: Fit model to your data by using the fit() method of the model \n",
    "\n",
    "**Step 5**: Apply the model to new data:\n",
    "    - For supervised learning, using the predict() method\n",
    "    - For unsupervised learning, using the predict() or transform() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;1.</font><font color=\"salmon\"> Näive Bayes Classification </font> </h2></a>\n",
    "\n",
    "We now extend sentiment analysis to texts that we have never seen before, and use a machine learning algorithm - Naïve Bayes Classification - to help us predict if a newly received review has positive or negative sentiment. Naïve Bayes Classification is the first machine learning algorithm we will learn in DS102.\n",
    "\n",
    "<a id='1.1'><h3> 1.1 Problem Setup</h3></a>\n",
    "\n",
    "Consider you have the following texts and their tagged sentiment **class**. \n",
    "$1$ represents a *positive sentiment* while $0$ represents a *negative sentiment*. \n",
    "There are only 2 possible classes in this problem.\n",
    "\n",
    "|ID | Text | Sentiment Class\n",
    "|---|---|--\n",
    "|1|`enjoy like`|$1$\n",
    "|2|`enjoy funny happy`|$1$\n",
    "|3|`hate boring like`|$0$\n",
    "|4|`like happy`|$1$\n",
    "|5|`boring dull`|$0$\n",
    "\n",
    "**Problem**: If we now have a new text `funny boring`. What is the predicted class of this new text?  Is it positive sentiment or negative sentiment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking closer\n",
    "\n",
    "Before we can do a prediction, we make the following observations about our data:\n",
    "\n",
    "* Total number of texts = 5\n",
    "* Number of texts that are tagged Positive = 3\n",
    "* Number of texts that are tagged Negative = 2\n",
    "\n",
    "* Probability of Positive texts = 3/5 = 0.6\n",
    "* Probability of Negative texts = 2/5 = 0.4\n",
    "\n",
    "There are 7 **unique** words in all the texts, making up the vocabulary.  These words are:\n",
    "\n",
    "* [ enjoy, like, funny, happy, hate, boring, dull ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at individual words and how frequent they appear in the data, we can generate the following **word frequency table** easily just by counting.\n",
    "\n",
    "| Word     | In Positive Text   | In Negative Text | In All Texts\n",
    "|----------|--------------------|------------------|--------------\n",
    "|boring    | 0                  | 2                | 2\n",
    "|dull      | 0                  | 1                | 1\n",
    "|enjoy     | 2                  | 0                | 2\n",
    "|funny     | 1                  | 0                | 1\n",
    "|happy     | 2                  | 0                | 2\n",
    "|hate      | 0                  | 1                | 1\n",
    "|like      | 2                  | 1                | 3\n",
    "|**total freq** | **7**         | **5**            | **12**\n",
    "\n",
    "### 1.2 Getting Probabilities for each Word\n",
    "\n",
    "What is the probability of having each word given either Positive Text or Negative Text?\n",
    "* P( Word | Positive) = ??  or  P( Word | Negative ) = ??\n",
    "\n",
    "| Word     | P(Word given +ve) | P(Word given -ve) | P(Word)\n",
    "|----------|-------------------|-------------------|--------\n",
    "|boring    | 0                 | 2/5               | 2/12\n",
    "|dull      | 0                 | 1/5               | 1/12\n",
    "|enjoy     | 2/7               | 0                 | 2/12\n",
    "|funny     | 1/7               | 0                 | 1/12\n",
    "|happy     | 2/7               | 0                 | 2/12\n",
    "|hate      | 0                 | 1/5               | 1/12\n",
    "|like      | 2/7               | 1/5               | 3/12\n",
    "\n",
    "Aa you can see, there are many 0 occurances of each word in the training data of each class. \n",
    "\n",
    "To avoid 0s later on in calculating sentiment scores, we can add 1 to the counts in each class.  This is known as **Laplace Smoothing with alpha=1**.\n",
    "\n",
    "### Example of Trained Result with Laplace Smoothing\n",
    "\n",
    "| Word     | P(Word given +ve) | P(Word given -ve) | P(Word)\n",
    "|----------|-------------------|-------------------|---------\n",
    "|boring    | 1/14              | 3/12              | 2/12\n",
    "|dull      | 1/14              | 2/12              | 1/12\n",
    "|enjoy     | 3/14              | 1/12              | 2/12\n",
    "|funny     | 2/14              | 1/12              | 1/12\n",
    "|happy     | 3/14              | 1/12              | 2/12\n",
    "|hate      | 1/14              | 2/12              | 1/12\n",
    "|like      | 3/14              | 2/12              | 3/12\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Bayes Theorem \n",
    "\n",
    "#### Let's take the word 'happy' for example\n",
    "\n",
    "<img src=\"https://i.imgur.com/XDfjIDR.png\" />\n",
    "\n",
    "### Let's say we have 100 texts\n",
    "\n",
    "Number inside the boxes are how many texts fall into that category\n",
    "\n",
    "<img src=\"https://i.imgur.com/RQsgqBr.png\" />\n",
    "\n",
    "#### For Multiple Words\n",
    "\n",
    "Just multiply the likelihood for each of the words that you have seen\n",
    "\n",
    "<img src=\"https://i.imgur.com/R5t9hi9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P1'><h2> <img src=\"https://cdn.shopify.com/s/files/1/1200/7374/products/book_aec28e76-52ec-44ab-bc01-41df1279c89f_550x825.png?v=1473897430\" width=25 align=\"left\"> <font color=\"darkorange\"> &nbsp; Practice Calculations </font><font color=\"skyblue\"> * </font></h2></a>\n",
    "\n",
    "Let's try it out on a few sentences. From above, we have our trained probabilities\n",
    "\n",
    "3 out of 5 documents are positive\n",
    "$$\n",
    "P(\\text{Positive}) = \\frac{3}{5}   \n",
    "$$\n",
    "\n",
    "2 out of 5 documents are negative\n",
    "$$\n",
    "P(\\text{Negative}) = \\frac{2}{5}  \n",
    "$$\n",
    "\n",
    "Word Probability Table\n",
    "\n",
    "|Word | P(W given Positive)| P(W given Negative)| P(Word)|\n",
    "|---|---|--|--|\n",
    "|`boring`|$\\frac{1}{14}$|$\\frac{3}{12}$|$\\frac{2}{12}$|\n",
    "|`dull`|$\\frac{1}{14}$ |$\\frac{2}{12}$|$\\frac{1}{12}$|\n",
    "|`enjoy`|$\\frac{3}{14}$ |$\\frac{1}{12}$|$\\frac{2}{12}$|\n",
    "|`funny`|$\\frac{2}{14}$|$\\frac{1}{12}$|$\\frac{1}{12}$|\n",
    "|`happy`|$\\frac{3}{14}$|$\\frac{1}{12}$|$\\frac{2}{12}$|\n",
    "|`hate`|$\\frac{1}{14}$|$\\frac{2}{12}$|$\\frac{1}{12}$|\n",
    "|`like`|$\\frac{3}{14}$|$\\frac{2}{12}$|$\\frac{3}{12}$|\n",
    "\n",
    "What is sentiment for the following new text?\n",
    "\n",
    "> **\"funny boring\"**\n",
    "\n",
    "Remember that the formulas:-\n",
    "\n",
    "* Likelihood of Positive Sentiment\n",
    "\n",
    "$$\n",
    "P(Positive | funny boring) = P(Positive)\\times\\frac{P(funny|Positive)}{P(funny)}\\times\\frac{P(boring|Positive)}{P(boring)}\n",
    "$$\n",
    "\n",
    "* Likelihood of Negative Sentiment\n",
    "\n",
    "$$\n",
    "P(Negative | funny boring) = P(Negative)\\times\\frac{P(funny|Negative)}{P(funny)}\\times\\frac{P(boring|Negative)}{P(boring)}\n",
    "$$\n",
    "\n",
    "\n",
    "Is it a positive or negative text?\n",
    "\n",
    "We check their sentiment scores to decide if the text is postive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score=0.44\n",
      "Negative Score=0.60\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "\n",
    "positive =  # Calculate positive score\n",
    "\n",
    "print(\"Positive Score={:.2f}\".format(positive))\n",
    "\n",
    "negative =   # Calculate negative score\n",
    "\n",
    "print(\"Negative Score={:.2f}\".format(negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If positive score > negative score, then the text is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the text positive? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the text positive?\", positive > negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ponder\n",
    "* Will \"boring funny\" have the same score?\n",
    "* Can it predict \"funny sad\"?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, Naive Bayes ignores how the words are ordered and treat them the same.\n",
    "# No, it can't classify \"funny sad\" since \"sad\" is not in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='2'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;2.</font><font color=\"salmon\"> Vectorizer </font> </h2></a>\n",
    "\n",
    "In order for Naive Bayes Classification to work, it would require a piece of text be transformed into numerical representation: a vector. \n",
    "\n",
    "#### Convert a Document to a Vector using `CountVectorizer`\n",
    "\n",
    "The following are the words in the corpus in the Naïve Bayes Classification example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_as_is = [\"This movie is amazing\",\n",
    "             \"I hate this movie\", \n",
    "             \"This movie is pretty good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using SkLearn's `CountVectorizer`, we can split each sentences into individual numbers representing a bunch of 1s and 0s. To do so, use `.fit_transform` with the list as an input. \n",
    "\n",
    "To get the matrix representation, use `.A`.\n",
    "\n",
    "To get the names of each columns, use the vectorizer's `.get_feature_names()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 1 0 1]\n",
      " [0 0 1 0 1 0 1]\n",
      " [0 1 0 1 1 1 1]]\n",
      "['amazing', 'good', 'hate', 'is', 'movie', 'pretty', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer Visualised as DataFrame \n",
    "\n",
    "This is just for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>good</th>\n",
       "      <th>hate</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>pretty</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This movie is amazing</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hate this movie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This movie is pretty good</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           amazing  good  hate  is  movie  pretty  this\n",
       "This movie is amazing            1     0     0   1      1       0     1\n",
       "I hate this movie                0     0     1   0      1       0     1\n",
       "This movie is pretty good        0     1     0   1      1       1     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = [\"This movie is amazing\",\"I hate this movie\", \"This movie is pretty good\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;3.</font><font color=\"salmon\"> Applied Naive Bayes - Popcorn Reviews </font> </h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `popcorn-reviews-5k.csv` training set. Add the option `sep=\"#\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5196_9</td>\n",
       "      <td>Human Tornado (1976) is in many ways a better ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2668_9</td>\n",
       "      <td>Chilling, majestic piece of cinematic fright, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9565_3</td>\n",
       "      <td>I cant say that Wargames The Dead Code is the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10271_10</td>\n",
       "      <td>This movie should not be compared to  The Stin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5639_7</td>\n",
       "      <td>Ive read the other reviews and found some to b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review  sentiment\n",
       "0    5196_9  Human Tornado (1976) is in many ways a better ...          1\n",
       "1    2668_9  Chilling, majestic piece of cinematic fright, ...          1\n",
       "2    9565_3  I cant say that Wargames The Dead Code is the ...          0\n",
       "3  10271_10  This movie should not be compared to  The Stin...          1\n",
       "4    5639_7  Ive read the other reviews and found some to b...          1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "popcorn_df = pd.read_csv('popcorn-reviews-5k.csv', sep=\"#\")\n",
    "\n",
    "popcorn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split \n",
    "\n",
    "Create new data frames from the raw df, as subsets\n",
    "\n",
    "* train (first 4500 rows) as `train_df`\n",
    "* test (last 500 rows) as `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = popcorn_df[:4500]\n",
    "test_df = popcorn_df[4500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Train the model given the reviews and the given sentiment. Recall that for `sentiment`, 1 represents a positive review and 0 represents a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a multinomial classifier using the training set using the features and the training set labels\n",
    "classifier = MultinomialNB().fit(matrix, \n",
    "                                 train_df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Now that we have trained our classifier, let's test it using the test set. We will check the actual prediction of a test example, and observe what the predicted model gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this movie. First, because it is a family movie. Second, because it offers a refreshing take on dealing with the news of HIV in a family, with far less hysteria than what I have normally seen in the movies. The brothers are very close, yet are not judgmental. Their desire to protect the youngest brother is noble, but not needed in the end. I understand that Leos choice on how to deal with his treatment may not have been the most popular one with people, but I believed it was the right choice for him. I cant believe that this was a french television programme. It had great production values. I gave this movie a ten, and I think you will too, once you have seen it.\n",
      "\n",
      "Actual Sentiment=  1\n",
      "\n",
      "Predicted Sentiment=  [1]\n"
     ]
    }
   ],
   "source": [
    "# Now, randomly sample an example from the test set.\n",
    "t_sample = test_df.sample()\n",
    "\n",
    "# Let's see the review in the test set and the actual sentiment.\n",
    "s = t_sample.iloc[0]['review']\n",
    "print(s)\n",
    "print()\n",
    "t = t_sample.iloc[0]['sentiment']\n",
    "print(\"Actual Sentiment= \", t)\n",
    "\n",
    "# Let's now see what class the model predicts for this test example.\n",
    "print()\n",
    "print(\"Predicted Sentiment= \", classifier.predict(vectorizer.transform([s])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credits**\n",
    "- [Kaggle (Bag of Words Meets Bags of Popcorn)](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) \n",
    "\n",
    "**Footnote**\n",
    "\n",
    "(1) : The reviews are partially processed. Only removal of special characters was performed. The remaining steps to be performed are stemming and removal of stop words.\n",
    "\n",
    "**Further Reading**\n",
    "Naïve Bayes can also be used for the following classification problems:\n",
    "\n",
    "1. Spam vs. Non-Spam in E-Mail Filtering\n",
    "2. Product classification using product titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
